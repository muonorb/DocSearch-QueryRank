# DocSearch (QueryRank): Intelligent Document Retrieval System

## ğŸ“Œ Project Overview
This project implements an **Information Retrieval System** that indexes a collection of documents, performs searches using multiple ranking models, and evaluates results using **TREC evaluation metrics**. The system works with the **Cranfield dataset**, containing 1,400 research abstracts.

## ğŸš€ Features
- **Indexing:** Converts XML-based documents into a structured format.
- **Search & Ranking Models:**
  - **Vector Space Model (VSM)** using TF-IDF & Cosine Similarity.
  - **BM25 Model** for probabilistic ranking.
  - **Language Model (LM)** for query likelihood ranking.
- **Evaluation:** Outputs results in TREC format for performance assessment.

## ğŸ“‚ Repository Structure
```
docsearch-queryrank/
â”‚â”€â”€ datasets/                 # Contains dataset files
â”‚   â”œâ”€â”€ cran.all.1400.xml     # Collection of documents
â”‚   â”œâ”€â”€ cran.qry.xml          # Queries for retrieval
â”‚   â”œâ”€â”€ cranqrel.trec.txt     # Relevance judgments
â”‚   â”œâ”€â”€ cran_all.csv          # Processed documents
â”‚   â”œâ”€â”€ cran_query.csv        # Processed queries
â”‚â”€â”€ src/                      # Source code
â”‚   â”œâ”€â”€ search_engine.py      # Main search engine script
â”‚   â”œâ”€â”€ xmltocsv.py           # XML to CSV conversion script
â”‚â”€â”€ results/                  # Stores search results
â”‚   â”œâ”€â”€ VSM_output.txt        # VSM ranking output
â”‚   â”œâ”€â”€ BM25_output.txt       # BM25 ranking output
â”‚   â”œâ”€â”€ LM_output.txt         # LM ranking output
â”‚â”€â”€ README.md                 # Project documentation
â”‚â”€â”€ requirements.txt          # Dependencies
```

## ğŸ›  Installation & Setup
1. **Clone the repository:**
```bash
git clone https://github.com/muonorb/DocSearch-QueryRank.git
cd DocSearch-QueryRank
```
2. **Install dependencies:**
```bash
pip install -r requirements.txt
```
3. **Run XML to CSV conversion:**
```bash
python src/xmltocsv.py
```
4. **Run the search engine:**
```bash
python src/main.py
```

## ğŸ“ˆ Ranking Methods
### 1ï¸âƒ£ Vector Space Model (VSM)
- Uses **TF-IDF weighting**.
- Computes **Cosine Similarity** between query and documents.

### 2ï¸âƒ£ BM25 (Best Matching 25)
- A probabilistic ranking function.
- Uses **term frequency & inverse document frequency**.

### 3ï¸âƒ£ Language Model (LM)
- Uses **Query Likelihood Model**.
- Computes probability of generating query from each document.

## ğŸ“Š Evaluation
The system generates ranked lists in **TREC format**, which can be evaluated using [trec_eval](https://github.com/terrierteam/jtreceval).

### ğŸ† Running TREC Evaluation
To evaluate your search engine performance using trec_eval, follow these steps:
```bash
git clone https://github.com/usnistgov/trec_eval.git
cd trec_eval
make CC=clang
make CC=gcc
../trec_eval -m all_trec cranqrel.trec.txt BM25_output.txt
```


## ğŸ“ License
This project is licensed under the MIT License.

